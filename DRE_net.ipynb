{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRE_net.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandruCS165/DRE_net_for_finding_covid/blob/main/DRE_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKd407nYGG_"
      },
      "source": [
        "# Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td58dK2Ch0wz",
        "outputId": "62480596-5c63-4dc1-b102-b194d055df1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT0iMnIyh5Pj",
        "outputId": "dfff30db-4206-4a33-94cd-2a180ccaae44"
      },
      "source": [
        "import torch\n",
        "devices = [d for d in range(torch.cuda.device_count())]\n",
        "device_names  = [torch.cuda.get_device_name(d) for d in devices]\n",
        "print(device_names)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tesla K80']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vznfe-0EkTTq"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGY-U7BhiWGE"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "PROPOSAL_NUM = 6\n",
        "NO_OF_EPOCHS = 4\n",
        "CAT_NUM = 6\n",
        "INPUT_SIZE = (448, 448)     # (448, 448)  # (w, h)\n",
        "LR = 0.0008                  # 0.002\n",
        "WD = 1e-4\n",
        "SAVE_FREQ = 2\n",
        "# resume = ''#'./20200223_152850/002.ckpt'\n",
        "test_model = 'model.ckpt'\n",
        "save_dir = './'\n",
        "BRIGHTNESS = 0.5\n",
        "SATURATION = 0.5\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "SD = [0.229, 0.224, 0.225]\n",
        "#resume=''"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PvVsCdXkQNs"
      },
      "source": [
        "# DataPreprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYuJho1JiDya"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "class DataPreprocessingTrain():\n",
        "    def __init__(self, root_dir):\n",
        "        \"\"\"\n",
        "        Class Usage(Construtor)\n",
        "            Used for Data augumentation and data preprocessing of training data\n",
        "\n",
        "            Parameters:\n",
        "            root_dir (String): Path of root directory for image dataset\n",
        "\n",
        "            Returns:\n",
        "                Returns nothing \n",
        "\n",
        "        \"\"\"\n",
        "        # image_file_lst stores the image file's path\n",
        "        self.image_file_lst = []     \n",
        "\n",
        "        # label_lst stores corresponding labels of image_file_lst                      \n",
        "        self.label_lst = []\n",
        "\n",
        "        # This code intialize the image_file_lst and label_lst\n",
        "        # LABEL = {0:\"no_nCoV\",1 :\"nCoV\"}\n",
        "        # root_dir = input/\n",
        "        Label = {0:\"no_nCoV\",1 :\"nCoV\"}\n",
        "        for label,image_dir in Label.items():\n",
        "            image_path = f'{root_dir}/{image_dir}'\n",
        "            self.image_file_lst += [f'{image_path}/{item}' for item in os.listdir(image_path)]\n",
        "            self.label_lst += [label]*len(os.listdir(image_path))\n",
        "        \n",
        "        # Shuffles the dataset\n",
        "        temp = list(zip(self.image_file_lst, self.label_lst))\n",
        "        random.shuffle(temp)\n",
        "        self.image_file_lst = [item[0] for item in temp]\n",
        "        self.label_lst = [item[1] for item in temp]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        __getitem__(getter)\n",
        "            Returns the preprocessed image with corresponding label and raw image \n",
        "\n",
        "            Parameters:\n",
        "                index (String): Index of image and label pair needed\n",
        "\n",
        "            Returns:\n",
        "                image (tensor): Return the Preprocessed image in tensor format\n",
        "                target (int): Returns the actual label of image(tensor)\n",
        "                img_raw (tensor): Return the raw image in tensor format\n",
        "        \"\"\"\n",
        "        image = np.array(Image.open(self.image_file_lst[index]))\n",
        "        target = self.label_lst[index]\n",
        "\n",
        "        #If image is gray scale change into RGB\n",
        "        if len(image.shape) == 2:\n",
        "            image = np.stack([image] * 3, 2)\n",
        "        \n",
        "        #take the copy of the image to img_raw\n",
        "        img_raw = image.copy()\n",
        "        image = Image.fromarray(image, mode='RGB')\n",
        "        image = transforms.Resize(INPUT_SIZE, transforms.InterpolationMode.BILINEAR)(image)\n",
        "        \n",
        "        #Data Augumentation \n",
        "        flg_H = 0\n",
        "        if np.random.randint(2) == 1:\n",
        "            flg_H = 1\n",
        "            image = transforms.RandomHorizontalFlip(p=1)(image)\n",
        "        image = transforms.ColorJitter(brightness=BRIGHTNESS, saturation=SATURATION)(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = transforms.Normalize(MEAN,SD)(image)\n",
        "        img_raw = Image.fromarray(img_raw, mode='RGB')\n",
        "        img_raw = transforms.Resize((600, 600), transforms.InterpolationMode.BILINEAR)(img_raw)\n",
        "        if flg_H == 1:\n",
        "            img_raw = transforms.RandomHorizontalFlip(p=1)(img_raw)\n",
        "        img_raw = transforms.ToTensor()(img_raw)\n",
        "        img_raw = transforms.Normalize(MEAN, SD)(img_raw)\n",
        "\n",
        "\n",
        "        return image, target, img_raw\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            No Parameters\n",
        "\n",
        "        Returns:\n",
        "            (int) : length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.label_lst)\n",
        "\n",
        "\n",
        "class DataPreprocessingVal():\n",
        "    def __init__(self, root_dir):\n",
        "        \"\"\"\n",
        "        Class Usage(Construtor)\n",
        "            Used for Data augumentation and data preprocessing of validation data and testing data\n",
        "            \n",
        "            Parameters:\n",
        "            root_dir (String): Path of root directory for image dataset\n",
        "\n",
        "            Returns:\n",
        "                Returns nothing \n",
        "\n",
        "        \"\"\"\n",
        "        # image_file_lst stores the image file's path\n",
        "        self.image_file_lst = []     \n",
        "        Label = {0:\"no_nCoV\",1 :\"nCoV\"}\n",
        "        # label_lst stores corresponding labels of image_file_lst                      \n",
        "        self.label_lst = []\n",
        "\n",
        "        # This code intialize the image_file_lst and label_lst\n",
        "        # Label = {0:\"no_nCoV\",1 :\"nCoV\"}\n",
        "        for label,image_dir in Label.items():\n",
        "            image_path = f'{root_dir}/{image_dir}'\n",
        "            self.image_file_lst += [f'{image_path}/{item}' for item in os.listdir(image_path)]\n",
        "            self.label_lst += [label]*len(os.listdir(image_path))\n",
        "        \n",
        "        # Shuffles the dataset\n",
        "        temp = list(zip(self.image_file_lst, self.label_lst))\n",
        "        random.shuffle(temp)\n",
        "        self.image_file_lst = [item[0] for item in temp]\n",
        "        self.label_lst = [item[1] for item in temp]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        __getitem__(getter)\n",
        "            Returns the preprocessed image with corresponding label and raw image \n",
        "\n",
        "            Parameters:\n",
        "                index (String): Index of image and label pair needed\n",
        "\n",
        "            Returns:\n",
        "                image (tensor): Return the Preprocessed image in tensor format\n",
        "                target (int): Returns the actual label of image(tensor)\n",
        "                img_raw (tensor): Return the raw image in tensor format\n",
        "        \"\"\"\n",
        "        image = np.array(Image.open(self.image_file_lst[index]))\n",
        "        target = self.label_lst[index]\n",
        "        #If image is gray scale change into RGB\n",
        "        if len(image.shape) == 2:\n",
        "            image = np.stack([image] * 3, 2)\n",
        "        \n",
        "        img_raw = image.copy()\n",
        "        image = Image.fromarray(image, mode='RGB')\n",
        "        image = transforms.Resize(INPUT_SIZE, transforms.InterpolationMode.BILINEAR)(image)\n",
        "        \n",
        "        #Data Augumentation \n",
        "        image = transforms.ColorJitter(brightness=BRIGHTNESS, saturation=SATURATION)(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = transforms.Normalize(MEAN,SD)(image)\n",
        "        img_raw = Image.fromarray(img_raw, mode='RGB')\n",
        "        img_raw = transforms.Resize((600, 600), transforms.InterpolationMode.BILINEAR)(img_raw)\n",
        "        img_raw = transforms.ToTensor()(img_raw)\n",
        "        img_raw = transforms.Normalize(MEAN, SD)(img_raw)\n",
        "\n",
        "\n",
        "        return image, target, img_raw\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        __len__(getter)\n",
        "\n",
        "            Parameters:\n",
        "                No Parameters\n",
        "\n",
        "\n",
        "            Returns:\n",
        "                (int) : length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.label_lst)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2beSlk5KkLMK"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqD61YZXiMhL"
      },
      "source": [
        "#\n",
        "# resnet link : https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        feature_map = x                    #feature1 --> (batchsize,2048,14,14)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = nn.Dropout(p=0.5)(x)\n",
        "        feature2 = x                    #\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x, feature_map, feature2\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth'))\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CaShmuW9ZPA",
        "outputId": "fbb6af12-e0be-40d9-9e76-0d926242ef79"
      },
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "m = resnet50(pretrained=True).to(device)\n",
        "m.avgpool = nn.AdaptiveAvgPool2d(1).to(device)\n",
        "m.fc = nn.Linear(512 * 4, 2).to(device)\n",
        "print()\n",
        "print(\"Summary of resnet50 for (3,448,448) \")\n",
        "print()\n",
        "summary(m, (3, 448, 448))\n",
        "print()\n",
        "print(\"Summary of resnet50 for (3,224,224) \")\n",
        "print()\n",
        "summary(m, (3, 224, 224))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of resnet50 for (3,448,448) \n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
            "            Conv2d-5         [-1, 64, 112, 112]           4,096\n",
            "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
            "              ReLU-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
            "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
            "             ReLU-10         [-1, 64, 112, 112]               0\n",
            "           Conv2d-11        [-1, 256, 112, 112]          16,384\n",
            "      BatchNorm2d-12        [-1, 256, 112, 112]             512\n",
            "           Conv2d-13        [-1, 256, 112, 112]          16,384\n",
            "      BatchNorm2d-14        [-1, 256, 112, 112]             512\n",
            "             ReLU-15        [-1, 256, 112, 112]               0\n",
            "       Bottleneck-16        [-1, 256, 112, 112]               0\n",
            "           Conv2d-17         [-1, 64, 112, 112]          16,384\n",
            "      BatchNorm2d-18         [-1, 64, 112, 112]             128\n",
            "             ReLU-19         [-1, 64, 112, 112]               0\n",
            "           Conv2d-20         [-1, 64, 112, 112]          36,864\n",
            "      BatchNorm2d-21         [-1, 64, 112, 112]             128\n",
            "             ReLU-22         [-1, 64, 112, 112]               0\n",
            "           Conv2d-23        [-1, 256, 112, 112]          16,384\n",
            "      BatchNorm2d-24        [-1, 256, 112, 112]             512\n",
            "             ReLU-25        [-1, 256, 112, 112]               0\n",
            "       Bottleneck-26        [-1, 256, 112, 112]               0\n",
            "           Conv2d-27         [-1, 64, 112, 112]          16,384\n",
            "      BatchNorm2d-28         [-1, 64, 112, 112]             128\n",
            "             ReLU-29         [-1, 64, 112, 112]               0\n",
            "           Conv2d-30         [-1, 64, 112, 112]          36,864\n",
            "      BatchNorm2d-31         [-1, 64, 112, 112]             128\n",
            "             ReLU-32         [-1, 64, 112, 112]               0\n",
            "           Conv2d-33        [-1, 256, 112, 112]          16,384\n",
            "      BatchNorm2d-34        [-1, 256, 112, 112]             512\n",
            "             ReLU-35        [-1, 256, 112, 112]               0\n",
            "       Bottleneck-36        [-1, 256, 112, 112]               0\n",
            "           Conv2d-37        [-1, 128, 112, 112]          32,768\n",
            "      BatchNorm2d-38        [-1, 128, 112, 112]             256\n",
            "             ReLU-39        [-1, 128, 112, 112]               0\n",
            "           Conv2d-40          [-1, 128, 56, 56]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
            "             ReLU-42          [-1, 128, 56, 56]               0\n",
            "           Conv2d-43          [-1, 512, 56, 56]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n",
            "           Conv2d-45          [-1, 512, 56, 56]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n",
            "             ReLU-47          [-1, 512, 56, 56]               0\n",
            "       Bottleneck-48          [-1, 512, 56, 56]               0\n",
            "           Conv2d-49          [-1, 128, 56, 56]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
            "             ReLU-51          [-1, 128, 56, 56]               0\n",
            "           Conv2d-52          [-1, 128, 56, 56]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
            "             ReLU-54          [-1, 128, 56, 56]               0\n",
            "           Conv2d-55          [-1, 512, 56, 56]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n",
            "             ReLU-57          [-1, 512, 56, 56]               0\n",
            "       Bottleneck-58          [-1, 512, 56, 56]               0\n",
            "           Conv2d-59          [-1, 128, 56, 56]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 56, 56]             256\n",
            "             ReLU-61          [-1, 128, 56, 56]               0\n",
            "           Conv2d-62          [-1, 128, 56, 56]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 56, 56]             256\n",
            "             ReLU-64          [-1, 128, 56, 56]               0\n",
            "           Conv2d-65          [-1, 512, 56, 56]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n",
            "             ReLU-67          [-1, 512, 56, 56]               0\n",
            "       Bottleneck-68          [-1, 512, 56, 56]               0\n",
            "           Conv2d-69          [-1, 128, 56, 56]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 56, 56]             256\n",
            "             ReLU-71          [-1, 128, 56, 56]               0\n",
            "           Conv2d-72          [-1, 128, 56, 56]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
            "             ReLU-74          [-1, 128, 56, 56]               0\n",
            "           Conv2d-75          [-1, 512, 56, 56]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n",
            "             ReLU-77          [-1, 512, 56, 56]               0\n",
            "       Bottleneck-78          [-1, 512, 56, 56]               0\n",
            "           Conv2d-79          [-1, 256, 56, 56]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 56, 56]             512\n",
            "             ReLU-81          [-1, 256, 56, 56]               0\n",
            "           Conv2d-82          [-1, 256, 28, 28]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
            "             ReLU-84          [-1, 256, 28, 28]               0\n",
            "           Conv2d-85         [-1, 1024, 28, 28]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n",
            "           Conv2d-87         [-1, 1024, 28, 28]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n",
            "             ReLU-89         [-1, 1024, 28, 28]               0\n",
            "       Bottleneck-90         [-1, 1024, 28, 28]               0\n",
            "           Conv2d-91          [-1, 256, 28, 28]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 28, 28]             512\n",
            "             ReLU-93          [-1, 256, 28, 28]               0\n",
            "           Conv2d-94          [-1, 256, 28, 28]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 28, 28]             512\n",
            "             ReLU-96          [-1, 256, 28, 28]               0\n",
            "           Conv2d-97         [-1, 1024, 28, 28]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n",
            "             ReLU-99         [-1, 1024, 28, 28]               0\n",
            "      Bottleneck-100         [-1, 1024, 28, 28]               0\n",
            "          Conv2d-101          [-1, 256, 28, 28]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 28, 28]             512\n",
            "            ReLU-103          [-1, 256, 28, 28]               0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Conv2d-104          [-1, 256, 28, 28]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 28, 28]             512\n",
            "            ReLU-106          [-1, 256, 28, 28]               0\n",
            "          Conv2d-107         [-1, 1024, 28, 28]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n",
            "            ReLU-109         [-1, 1024, 28, 28]               0\n",
            "      Bottleneck-110         [-1, 1024, 28, 28]               0\n",
            "          Conv2d-111          [-1, 256, 28, 28]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 28, 28]             512\n",
            "            ReLU-113          [-1, 256, 28, 28]               0\n",
            "          Conv2d-114          [-1, 256, 28, 28]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 28, 28]             512\n",
            "            ReLU-116          [-1, 256, 28, 28]               0\n",
            "          Conv2d-117         [-1, 1024, 28, 28]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n",
            "            ReLU-119         [-1, 1024, 28, 28]               0\n",
            "      Bottleneck-120         [-1, 1024, 28, 28]               0\n",
            "          Conv2d-121          [-1, 256, 28, 28]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 28, 28]             512\n",
            "            ReLU-123          [-1, 256, 28, 28]               0\n",
            "          Conv2d-124          [-1, 256, 28, 28]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 28, 28]             512\n",
            "            ReLU-126          [-1, 256, 28, 28]               0\n",
            "          Conv2d-127         [-1, 1024, 28, 28]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n",
            "            ReLU-129         [-1, 1024, 28, 28]               0\n",
            "      Bottleneck-130         [-1, 1024, 28, 28]               0\n",
            "          Conv2d-131          [-1, 256, 28, 28]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 28, 28]             512\n",
            "            ReLU-133          [-1, 256, 28, 28]               0\n",
            "          Conv2d-134          [-1, 256, 28, 28]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 28, 28]             512\n",
            "            ReLU-136          [-1, 256, 28, 28]               0\n",
            "          Conv2d-137         [-1, 1024, 28, 28]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n",
            "            ReLU-139         [-1, 1024, 28, 28]               0\n",
            "      Bottleneck-140         [-1, 1024, 28, 28]               0\n",
            "          Conv2d-141          [-1, 512, 28, 28]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 28, 28]           1,024\n",
            "            ReLU-143          [-1, 512, 28, 28]               0\n",
            "          Conv2d-144          [-1, 512, 14, 14]       2,359,296\n",
            "     BatchNorm2d-145          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-146          [-1, 512, 14, 14]               0\n",
            "          Conv2d-147         [-1, 2048, 14, 14]       1,048,576\n",
            "     BatchNorm2d-148         [-1, 2048, 14, 14]           4,096\n",
            "          Conv2d-149         [-1, 2048, 14, 14]       2,097,152\n",
            "     BatchNorm2d-150         [-1, 2048, 14, 14]           4,096\n",
            "            ReLU-151         [-1, 2048, 14, 14]               0\n",
            "      Bottleneck-152         [-1, 2048, 14, 14]               0\n",
            "          Conv2d-153          [-1, 512, 14, 14]       1,048,576\n",
            "     BatchNorm2d-154          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-155          [-1, 512, 14, 14]               0\n",
            "          Conv2d-156          [-1, 512, 14, 14]       2,359,296\n",
            "     BatchNorm2d-157          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-158          [-1, 512, 14, 14]               0\n",
            "          Conv2d-159         [-1, 2048, 14, 14]       1,048,576\n",
            "     BatchNorm2d-160         [-1, 2048, 14, 14]           4,096\n",
            "            ReLU-161         [-1, 2048, 14, 14]               0\n",
            "      Bottleneck-162         [-1, 2048, 14, 14]               0\n",
            "          Conv2d-163          [-1, 512, 14, 14]       1,048,576\n",
            "     BatchNorm2d-164          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-165          [-1, 512, 14, 14]               0\n",
            "          Conv2d-166          [-1, 512, 14, 14]       2,359,296\n",
            "     BatchNorm2d-167          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-168          [-1, 512, 14, 14]               0\n",
            "          Conv2d-169         [-1, 2048, 14, 14]       1,048,576\n",
            "     BatchNorm2d-170         [-1, 2048, 14, 14]           4,096\n",
            "            ReLU-171         [-1, 2048, 14, 14]               0\n",
            "      Bottleneck-172         [-1, 2048, 14, 14]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                    [-1, 2]           4,098\n",
            "================================================================\n",
            "Total params: 23,512,130\n",
            "Trainable params: 23,512,130\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.30\n",
            "Forward/backward pass size (MB): 1146.16\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 1238.14\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Summary of resnet50 for (3,224,224) \n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                    [-1, 2]           4,098\n",
            "================================================================\n",
            "Total params: 23,512,130\n",
            "Trainable params: 23,512,130\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 89.69\n",
            "Estimated Total Size (MB): 376.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHSgKaWYkHHr"
      },
      "source": [
        "# Anchors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nufCBn5PiPXy"
      },
      "source": [
        "import numpy as np\n",
        "default_anchors_small = (\n",
        "    dict(stride=32, size=48),\n",
        "    dict(stride=64, size=96),\n",
        ")\n",
        "default_anchors_large = (\n",
        "    dict(stride=128, size=192),\n",
        ")\n",
        "def intialize_anchor_maps(setting='small'):\n",
        "    \"\"\"\n",
        "    intialize_anchor_maps\n",
        "    This function is used to set the anchors in default position before training data\n",
        "\n",
        "    Parameter:\n",
        "        settings (String): This parameter determines the size of the anchors\n",
        "\n",
        "    Return: \n",
        "        edge_anchors (List): list of the egde anchors with top-left corner(y0,x0) and bottom right corner(y1,x1) (y0, x0, y1, x1)\n",
        "    \"\"\"\n",
        "    if setting == 'small':\n",
        "        anchors_setting = default_anchors_small\n",
        "    else:\n",
        "        anchors_setting = default_anchors_large\n",
        "\n",
        "    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
        "    input_shape = np.array(INPUT_SIZE, dtype=int)\n",
        "\n",
        "    for anchor_info in anchors_setting:\n",
        "\n",
        "        stride = anchor_info['stride']\n",
        "        size = anchor_info['size']\n",
        "\n",
        "        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride)\n",
        "        output_map_shape = output_map_shape.astype(np.int)\n",
        "        output_shape = tuple(output_map_shape) + (4,)\n",
        "        start = stride / 2.\n",
        "        oy = np.arange(start, start + stride * output_shape[0], stride)\n",
        "        oy = oy.reshape(output_shape[0], 1)\n",
        "        ox = np.arange(start, start + stride * output_shape[1], stride)\n",
        "        ox = ox.reshape(1, output_shape[1])\n",
        "        center_anchor_map = np.zeros(output_shape, dtype=np.float32)\n",
        "        center_anchor_map[:, :, 0] = oy\n",
        "        center_anchor_map[:, :, 1] = ox\n",
        "        edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - size / 2.,\n",
        "                                            center_anchor_map[..., :2] + size / 2.),\n",
        "                                            axis=-1)\n",
        "        edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
        "\n",
        "    return edge_anchors\n",
        "\n",
        "#*\n",
        "def hard_nms(cdds, topk=6, iou_thresh=0.25):\n",
        "\n",
        "    cdds = cdds.copy()\n",
        "    indices = np.argsort(cdds[:, 0])\n",
        "    cdds = cdds[indices]\n",
        "    cdd_results = []\n",
        "\n",
        "    res = cdds\n",
        "\n",
        "    while res.any():\n",
        "        cdd = res[-1]\n",
        "        cdd_results.append(cdd)\n",
        "        if len(cdd_results) == topk:\n",
        "            return np.array(cdd_results)\n",
        "        res = res[:-1]\n",
        "\n",
        "        start_max = np.maximum(res[:, 1:3], cdd[1:3])\n",
        "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
        "        lengths = end_min - start_max\n",
        "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
        "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
        "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
        "            cdd[4] - cdd[2]) - intersec_map)\n",
        "        res = res[iou_map_cur <= iou_thresh]\n",
        "\n",
        "    return np.array(cdd_results)\n",
        "\n",
        "def get_xy(y0, x0, y1, x1, size=448):\n",
        "    pad_size = size//2\n",
        "    \n",
        "    y0 = np.max([y0, pad_size])\n",
        "    y0 = np.min([y0, size+pad_size])\n",
        "    \n",
        "    x0 = np.max([x0, pad_size])\n",
        "    x0 = np.min([x0, size+pad_size])\n",
        "    \n",
        "    y1 = np.max([y1, pad_size])\n",
        "    y1 = np.min([y1, size+pad_size])\n",
        "    \n",
        "    x1 = np.max([x1, pad_size])\n",
        "    x1 = np.min([x1, size+pad_size])\n",
        "    \n",
        "    return y0, x0, y1, x1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLiW8zRgkCST"
      },
      "source": [
        "# DRE-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyRdwq3Bib7r"
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class FPN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FPN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2048, 128, 3, 1, 1)  # 2048 --> 128  , 3 X 3, strides = 1,padding = 1\n",
        "        self.conv2 = nn.Conv2d(128, 128, 3, 2, 1)   \n",
        "        self.conv3 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.order1 = nn.Conv2d(128, 1, 1, 1, 0)\n",
        "        self.order2 = nn.Conv2d(128, 1, 1, 1, 0)\n",
        "        self.order3 = nn.Conv2d(128, 1, 1, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x1 = self.ReLU(self.conv1(x))\n",
        "        x2 = self.ReLU(self.conv2(x1))\n",
        "        x3 = self.ReLU(self.conv3(x2))\n",
        "        t1 = self.order1(x1).view(batch_size, -1)\n",
        "        t2 = self.order2(x2).view(batch_size, -1)\n",
        "        t = self.order3(x3).view(batch_size, -1)\n",
        "        return torch.cat((t1, t2), dim=1), t\n",
        "\n",
        "\n",
        "class DRE_net(nn.Module):\n",
        "    def __init__(self, topK=6, n_class=2):\n",
        "        super(DRE_net, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.resNet = resnet50(pretrained=True)\n",
        "        self.resNet.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.resNet.fc = nn.Linear(512 * 4, self.n_class)\n",
        "        self.fpn_net = FPN()\n",
        "        self.topK = topK\n",
        "        self.mlp = nn.Linear(2048 * (CAT_NUM + 1 + 1), self.n_class)\n",
        "        self.sub_mlp = nn.Linear(512 * 4, self.n_class)\n",
        "        \n",
        "        self.pad_side = 224\n",
        "\n",
        "        #intializing the edge anchors\n",
        "        edge_anchors_small= intialize_anchor_maps(setting='small')\n",
        "        self.edge_anchors_small = (edge_anchors_small + 224).astype(np.int)\n",
        "        edge_anchors_large= intialize_anchor_maps(setting='large')\n",
        "        self.edge_anchors_large = (edge_anchors_large + 224).astype(np.int)\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, image, img_raw):\n",
        "\n",
        "        #image = (batch_size,3,448,448)\n",
        "        #img_raw = (batch_size,3,600,600)\n",
        "        resnet_out, feature_map, feature = self.resNet(image)   # x, feature1,feature2\n",
        "        rn_logits = resnet_out\n",
        "        image_pad = F.pad(image, (self.pad_side, self.pad_side, \n",
        "                          self.pad_side, self.pad_side), mode='constant', value=0)\n",
        "        #pad = 224\n",
        "        batch = image.size(0)\n",
        "       \n",
        "        # region_small = (batch,245,1)\n",
        "        # region_large = (batch,16,1)\n",
        "        region_score_small, region_score_large = self.fpn_net(feature_map.detach())\n",
        "        all_subimg_small = [\n",
        "            np.concatenate((x.reshape(-1, 1), \n",
        "                            self.edge_anchors_small.copy(), \n",
        "                            np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n",
        "            for x in region_score_small.data.cpu().numpy()]\n",
        "        top_K_subimg_small = [hard_nms(x, topk=self.topK//2, iou_thresh=0.1) for x in all_subimg_small]\n",
        "        top_K_subimg_small = np.array(top_K_subimg_small)\n",
        "        top_K_index_small = top_K_subimg_small[:, :, -1].astype(np.int)\n",
        "        top_K_index_small = torch.from_numpy(top_K_index_small).cuda()\n",
        "        top_K_prob_small = torch.gather(region_score_small, dim=1, index=top_K_index_small)\n",
        "\n",
        "\n",
        "\n",
        "        all_subimg_large = [\n",
        "            np.concatenate((x.reshape(-1, 1), \n",
        "                            self.edge_anchors_large.copy(), \n",
        "                            np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n",
        "            for x in region_score_large.data.cpu().numpy()]\n",
        "        top_K_subimg_large = [hard_nms(x, topk=self.topK//2, iou_thresh=0.1) for x in all_subimg_large]\n",
        "        top_K_subimg_large = np.array(top_K_subimg_large)\n",
        "        top_K_index_large = top_K_subimg_large[:, :, -1].astype(np.int)\n",
        "        top_K_index_large = torch.from_numpy(top_K_index_large).cuda()\n",
        "        top_K_prob_large = torch.gather(region_score_large, dim=1, index=top_K_index_large)\n",
        "        \n",
        "        sub_imgs = torch.zeros([batch, self.topK, 3, 224, 224]).cuda()\n",
        "\n",
        "\n",
        "        #upSampling the all small and large sub images into 224 X 224\n",
        "        for i in range(batch):\n",
        "            for j in range(self.topK//2):\n",
        "                [y0, x0, y1, x1] = top_K_subimg_small[i][j, 1:5].astype(np.int)\n",
        "                sub_imgs[i:i + 1, j] = F.interpolate(image_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n",
        "                                                      align_corners=True)\n",
        "                [y0, x0, y1, x1] = top_K_subimg_large[i][j, 1:5].astype(np.int)\n",
        "                sub_imgs[i:i + 1, j+self.topK//2] = F.interpolate(image_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n",
        "                                                      align_corners=True)\n",
        "                \n",
        "        sub_imgs = sub_imgs.view(batch * self.topK, 3, 224, 224)\n",
        "        #sending all subimgs of size 224 X 224 to resnet\n",
        "        _, _, subimg_features = self.resNet(sub_imgs.detach())\n",
        "        subimg_feature = subimg_features.view(batch, self.topK, -1)\n",
        "        subimg_feature = subimg_feature[:, :CAT_NUM, ...].contiguous()\n",
        "        #changing the dimension into (batch)\n",
        "        subimg_feature = subimg_feature.view(batch, -1)\n",
        "\n",
        "\n",
        "\n",
        "        image2 = image.clone()\n",
        "        for bs in range(batch):\n",
        "            [y0, x0, y1, x1] = top_K_subimg_large[bs][0, 1:5].astype(np.int)\n",
        "            y0, x0, y1, x1 = get_xy(y0, x0, y1, x1)\n",
        "            y0 = np.int((y0 - 224)/448*600)\n",
        "            x0 = np.int((x0 - 224)/448*600)\n",
        "            y1 = np.int((y1 - 224)/448*600)\n",
        "            x1 = np.int((x1 - 224)/448*600)\n",
        "            image2[bs] = F.interpolate(\n",
        "                    img_raw[bs:bs + 1, :, y0:y1, x0:x1],\n",
        "                    size=(448, 448), mode='bilinear', align_corners=True)\n",
        "        _, _, feature2 = self.resNet(image2.detach()) # \n",
        "        \n",
        "        top_K_index = torch.cat([top_K_index_small, top_K_index_large], 1)\n",
        "        top_K_prob = torch.cat([top_K_prob_small, top_K_prob_large], 1)\n",
        "        # mlp_logits have the shape: Batch*200\n",
        "        mlp_in = torch.cat([subimg_feature, feature, feature2], dim=1)\n",
        "        mlp_logits = self.mlp(mlp_in)\n",
        "        # sub_logits have the shape: Batch*topK*200\n",
        "        sub_logits = self.sub_mlp(subimg_features).view(batch, self.topK, -1)\n",
        "        return [rn_logits, mlp_logits, sub_logits, \n",
        "                top_K_index, top_K_prob]\n",
        "\n",
        "#*\n",
        "def list_loss(logits, targets):\n",
        "    temp = F.log_softmax(logits, -1)\n",
        "    loss = [-temp[i][targets[i].item()] for i in range(logits.size(0))]\n",
        "    return torch.stack(loss)\n",
        "\n",
        "#*\n",
        "def ranking_loss(score, targets, proposal_num=PROPOSAL_NUM):\n",
        "    loss = Variable(torch.zeros(1).cuda())\n",
        "    batch_size = score.size(0)\n",
        "    for i in range(proposal_num):\n",
        "        targets_p = (targets > targets[:, i].unsqueeze(1)).type(torch.cuda.FloatTensor)\n",
        "        pivot = score[:, i].unsqueeze(1)\n",
        "        loss_p = (1 - pivot + score) * targets_p\n",
        "        loss_p = torch.sum(F.relu(loss_p))\n",
        "        loss += loss_p\n",
        "    return loss / batch_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9F97mO1990G",
        "outputId": "1d372a95-ba65-4311-eeb8-276edc262d6f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "m = FPN().to(device)\n",
        "print()\n",
        "print(\"Summary of FPNs\")\n",
        "print()\n",
        "summary(m, (2048,14,14))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of FPNs\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 14, 14]       2,359,424\n",
            "              ReLU-2          [-1, 128, 14, 14]               0\n",
            "            Conv2d-3            [-1, 128, 7, 7]         147,584\n",
            "              ReLU-4            [-1, 128, 7, 7]               0\n",
            "            Conv2d-5            [-1, 128, 4, 4]         147,584\n",
            "              ReLU-6            [-1, 128, 4, 4]               0\n",
            "            Conv2d-7            [-1, 1, 14, 14]             129\n",
            "            Conv2d-8              [-1, 1, 7, 7]             129\n",
            "            Conv2d-9              [-1, 1, 4, 4]             129\n",
            "================================================================\n",
            "Total params: 2,654,979\n",
            "Trainable params: 2,654,979\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.53\n",
            "Forward/backward pass size (MB): 0.51\n",
            "Params size (MB): 10.13\n",
            "Estimated Total Size (MB): 12.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URh2wLq7j8tD"
      },
      "source": [
        "# Main "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqQhVyHqieFe",
        "outputId": "91d62d2c-aa5f-4382-8555-cead2c224451"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/gdrive/MyDrive/Mini-Project/COVID19-CT-main/local_traniner/model\")\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "import numpy as np\n",
        "\n",
        "# read dataset\n",
        "\n",
        "train_path = '../input/train/'\n",
        "val_path = '../input/val/'\n",
        "test_path = '../input/test/'\n",
        "trainset = DataPreprocessingTrain(root_dir=train_path)\n",
        "valset = DataPreprocessingVal(root_dir=val_path)\n",
        "testset = DataPreprocessingVal(root_dir=test_path)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2, drop_last=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2, drop_last=False)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2, drop_last=False)\n",
        "\n",
        "n_class = 2\n",
        "print(\"dataset loading done\")\n",
        "\n",
        "# define model\n",
        "model = DRE_net(topK=PROPOSAL_NUM, n_class=n_class)\n",
        "creterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# define optimizers\n",
        "rn_parameters = list(model.resNet.parameters())\n",
        "fpn_parameters = list(model.fpn_net.parameters())\n",
        "mlp_parameters = list(model.mlp.parameters())\n",
        "submlp_parameters = list(model.sub_mlp.parameters())\n",
        "\n",
        "rn_optimizer = torch.optim.SGD(rn_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "mlp_optimizer = torch.optim.SGD(mlp_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "fpn_optimizer = torch.optim.SGD(fpn_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "submlp_optimizer = torch.optim.SGD(submlp_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "\n",
        "model = model.cuda()\n",
        "model = DataParallel(model)\n",
        "\n",
        "print(f\"Starting training\")\n",
        "for epoch in range(1, NO_OF_EPOCHS + 1):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "    train_loss = 0\n",
        "#===================================================================================================================\n",
        "#\n",
        "#                     Training \n",
        "#\n",
        "#===================================================================================================================\n",
        "    for i, data in enumerate(trainloader):\n",
        "        image, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "        batch_size = image.size(0)\n",
        "\n",
        "        #reset the grad\n",
        "        rn_optimizer.zero_grad()\n",
        "        fpn_optimizer.zero_grad()\n",
        "        mlp_optimizer.zero_grad()\n",
        "        submlp_optimizer.zero_grad()\n",
        "\n",
        "        #input the batch images\n",
        "        rn_logits, mlp_logits, sub_logits, _, top_k_prob = model(image, img_raw)\n",
        "\n",
        "        #get the loss \n",
        "        fpn_loss = list_loss(sub_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                    label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n",
        "        rn_loss = creterion(rn_logits, label)\n",
        "        mlp_loss = creterion(mlp_logits, label)\n",
        "        rank_loss = ranking_loss(top_k_prob, fpn_loss)\n",
        "        submlp_loss = creterion(sub_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                 label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
        "\n",
        "        total_loss = rn_loss + rank_loss + mlp_loss + submlp_loss\n",
        "\n",
        "        #take gradient\n",
        "        total_loss.backward()\n",
        "\n",
        "        #update the parameters\n",
        "        rn_optimizer.step()\n",
        "        fpn_optimizer.step()\n",
        "        mlp_optimizer.step()\n",
        "        submlp_optimizer.step()\n",
        "        \n",
        "        _, mlp_predict = torch.max(mlp_logits, 1)\n",
        "        total += batch_size\n",
        "        train_correct += torch.sum(mlp_predict.data == label.data)\n",
        "        train_acc = float(train_correct) / total\n",
        "        train_loss += mlp_loss.item() * batch_size\n",
        "    train_loss = train_loss / total\n",
        "    print()\n",
        "    print(\"Train accuracy\")\n",
        "    print(\n",
        "            'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n",
        "                 epoch,\n",
        "                 train_loss,\n",
        "                 train_acc,\n",
        "                 total))\n",
        "    if epoch % SAVE_FREQ == 0 :\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "#=======================================================================================================\n",
        "#\n",
        "#                   Validation\n",
        "#\n",
        "#=======================================================================================================\n",
        "        for i, data in enumerate(valloader):\n",
        "            with torch.no_grad():\n",
        "                image, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                batch_size = image.size(0)\n",
        "                _, mlp_logits, _, _, _, = model(image, img_raw)\n",
        "                # calculating loss\n",
        "                mlp_loss = creterion(mlp_logits, label)\n",
        "\n",
        "                # calculating accuracy\n",
        "                _, mlp_predict = torch.max(mlp_logits, 1)\n",
        "              \n",
        "                total += batch_size\n",
        "                train_correct += torch.sum(mlp_predict.data == label.data)\n",
        "                train_loss += mlp_loss.item() * batch_size\n",
        "        train_acc = float(train_correct) / total\n",
        "        train_loss = train_loss / total\n",
        "        print()\n",
        "        print(\"Validation Accuracy\")\n",
        "        print(\n",
        "             'epoch:{} - val loss: {:.3f} and val acc: {:.3f} total sample: {}'.format(\n",
        "                 epoch,\n",
        "                 train_loss,\n",
        "                 train_acc,\n",
        "                 total))\n",
        "#===========================================================================================================\n",
        "#\n",
        "#                   Testing\n",
        "#\n",
        "#============================================================================================================\n",
        "\t      # evaluation on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(testloader):\n",
        "            with torch.no_grad():\n",
        "                image, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                batch_size = image.size(0)\n",
        "                _, mlp_logits, _, _, _ = model(image, img_raw)\n",
        "                # calculating loss\n",
        "                mlp_loss = creterion(mlp_logits, label)\n",
        "\n",
        "                # calculating accuracy\n",
        "                _, mlp_predict = torch.max(mlp_logits, 1)\n",
        "\n",
        "                total += batch_size\n",
        "                test_correct += torch.sum(mlp_predict.data == label.data)\n",
        "                test_loss += mlp_loss.item() * batch_size\n",
        "        test_acc = float(test_correct) / total\n",
        "        test_loss = test_loss / total\n",
        "\n",
        "        print()\n",
        "        print(\"Test accuracy \")\n",
        "        print(\n",
        "             'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n",
        "                 epoch,\n",
        "                 test_loss,\n",
        "                 test_acc,\n",
        "                total))\n",
        "\n",
        "print('training completed')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset loading done\n",
            "Starting training\n",
            "\n",
            "Train accuracy\n",
            "epoch:1 - train loss: 1.197 and train acc: 0.703 total sample: 1148\n",
            "\n",
            "Train accuracy\n",
            "epoch:2 - train loss: 0.951 and train acc: 0.760 total sample: 1148\n",
            "\n",
            "Validation Accuracy\n",
            "epoch:2 - val loss: 0.638 and val acc: 0.855 total sample: 1148\n",
            "\n",
            "Test accuracy \n",
            "epoch:2 - test loss: 1.164 and test acc: 0.804 total sample: 567\n",
            "\n",
            "Train accuracy\n",
            "epoch:3 - train loss: 0.671 and train acc: 0.780 total sample: 1148\n",
            "\n",
            "Train accuracy\n",
            "epoch:4 - train loss: 0.489 and train acc: 0.828 total sample: 1148\n",
            "\n",
            "Validation Accuracy\n",
            "epoch:4 - val loss: 0.871 and val acc: 0.856 total sample: 1148\n",
            "\n",
            "Test accuracy \n",
            "epoch:4 - test loss: 1.769 and test acc: 0.795 total sample: 567\n",
            "training completed\n"
          ]
        }
      ]
    }
  ]
}