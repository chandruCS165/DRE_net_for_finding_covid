{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYQ2jwOWSI8AkCcTsjsdQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandruCS165/DRE_net_for_finding_covid/blob/main/keras_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkbokxKgdina"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class CropImage(keras.engine.Layer):\n",
        "    def __init__(self, nbox, img_size=224, **kwargs):\n",
        "        self.nbox = nbox\n",
        "        self.w = img_size\n",
        "        self.h = img_size\n",
        "        super(CropImage, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        image_pad = inputs[0]\n",
        "        regions = inputs[1]\n",
        "        regions = K.cast(regions, tf.float32)\n",
        "        regions = K.reshape(regions, (-1, 4))\n",
        "        regions_normalized = regions / K.cast(K.int_shape(image_pad)[1], tf.float32)\n",
        "        box_ind = tf.range(K.shape(image_pad)[0])\n",
        "        box_ind = K.repeat_elements(box_ind, self.nbox, axis=0)\n",
        "        self.part_images = tf.image.crop_and_resize(image_pad, regions_normalized, box_ind, (self.w, self.h))\n",
        "        return self.part_images\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None,) + K.int_shape(self.part_images)[1:]\n",
        "\n",
        "class Proposals(keras.engine.Layer):\n",
        "    def __init__(self, PROPOSAL_NUM, pad_side=224, **kwargs):\n",
        "        self.PROPOSAL_NUM = PROPOSAL_NUM\n",
        "        self.pad_side = pad_side\n",
        "        edge_anchors = generate_default_anchor_maps()\n",
        "        self.anchors = (edge_anchors + pad_side).astype(np.int32).astype(np.float32)\n",
        "        super(Proposals, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        rpn_score = inputs\n",
        "        indices = K.map_fn(lambda x: tf.image.non_max_suppression(self.anchors, K.cast(x, tf.float32),\n",
        "                                          self.PROPOSAL_NUM, iou_threshold=0.25, name='nms'), rpn_score, dtype=tf.int32)\n",
        "        proposals = K.map_fn(lambda x: K.gather(self.anchors, K.cast(x, tf.int32)), indices, dtype=tf.float32)\n",
        "        scores = K.map_fn(lambda x: K.gather(x[0], K.cast(x[1], tf.int32)), (rpn_score, indices), dtype=tf.float32)\n",
        "        scores = K.expand_dims(scores, axis=-1)\n",
        "        results = K.concatenate([proposals, scores], axis=-1)\n",
        "        self.results = results\n",
        "        return self.results\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None,) + K.int_shape(self.results)[1:]\n",
        "\n",
        "def res50(num_cls):\n",
        "    inputs = Input(shape=(None, None, 3))\n",
        "    base_model = ResNet50(include_top=False, input_tensor=inputs, weights='imagenet', pooling='avg')\n",
        "    feature1 = base_model.get_layer(\"activation_49\").output\n",
        "    feature2 = base_model.output\n",
        "    feature2 = Dropout(rate=0.5)(feature2)\n",
        "    resnet_out = Dense(num_cls, activation='softmax',\n",
        "                       kernel_initializer='he_uniform',\n",
        "                       kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                       bias_regularizer=regularizers.l2(weight_decay))(feature2)\n",
        "    return keras.models.Model(inputs, [resnet_out, feature1, feature2], name='raw')\n",
        "\n",
        "def proposalnet():\n",
        "    inputs = Input(shape=(None, None, 2048))\n",
        "    down1 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same',\n",
        "                   kernel_initializer='he_uniform',\n",
        "                   kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                   bias_regularizer=regularizers.l2(weight_decay))(inputs)\n",
        "    d1 = ReLU()(down1)\n",
        "    down2 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',\n",
        "                   kernel_initializer='he_uniform',\n",
        "                   kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                   bias_regularizer=regularizers.l2(weight_decay))(d1)\n",
        "    d2 = ReLU()(down2)\n",
        "    down3 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',\n",
        "                   kernel_initializer='he_uniform',\n",
        "                   kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                   bias_regularizer=regularizers.l2(weight_decay))(d2)\n",
        "    d3 = ReLU()(down3)\n",
        "\n",
        "    t1 = Reshape((-1,))(Conv2D(filters=6, kernel_size=1, strides=1,\n",
        "                               kernel_initializer='he_uniform',\n",
        "                               kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                               bias_regularizer=regularizers.l2(weight_decay))(d1))\n",
        "    t2 = Reshape((-1,))(Conv2D(filters=6, kernel_size=1, strides=1,\n",
        "                               kernel_initializer='he_uniform',\n",
        "                               kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                               bias_regularizer=regularizers.l2(weight_decay))(d2))\n",
        "    t3 = Reshape((-1,))(Conv2D(filters=9, kernel_size=1, strides=1,\n",
        "                               kernel_initializer='he_uniform',\n",
        "                               kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                               bias_regularizer=regularizers.l2(weight_decay))(d3))\n",
        "\n",
        "    t = Concatenate(axis=-1)([t1,t2,t3])\n",
        "    return keras.models.Model(inputs, t)\n",
        "\n",
        "def concatnet(num_cls, topN):\n",
        "    inputs = Input(shape=(2048*(topN+1),))\n",
        "    out = Dense(num_cls, activation='softmax',\n",
        "                kernel_initializer='he_uniform',\n",
        "                kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                bias_regularizer=regularizers.l2(weight_decay))(inputs)\n",
        "    return keras.models.Model(inputs, out, name='concat')\n",
        "\n",
        "def partclsnet(num_cls):\n",
        "    inputs = Input(shape=(2048,))\n",
        "    out = Dense(num_cls, activation='softmax',\n",
        "                kernel_initializer='he_uniform',\n",
        "                kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                bias_regularizer=regularizers.l2(weight_decay))(inputs)\n",
        "    return keras.models.Model(inputs, out)\n",
        "\n",
        "def create_attention_model(topN, PROPOSAL_NUM, num_cls, pad_side=224):\n",
        "    input_image = Input(shape=(448, 448, 3))\n",
        "\n",
        "    pretrained_model = res50(num_cls)\n",
        "    proposal_net = proposalnet()\n",
        "    concat_net = concatnet(num_cls, topN)\n",
        "    partcls_net = partclsnet(num_cls)\n",
        "\n",
        "    resnet_out, rpn_feature, feature = pretrained_model(input_image)\n",
        "    rpn_feature = Lambda(lambda x: tf.stop_gradient(x))(rpn_feature)\n",
        "    rpn_score = proposal_net(rpn_feature)\n",
        "\n",
        "    image_pad = Lambda(lambda x: K.spatial_2d_padding(x,\n",
        "                padding=((pad_side, pad_side), (pad_side, pad_side))))(input_image)\n",
        "\n",
        "    top_n_cdds = Proposals(PROPOSAL_NUM=PROPOSAL_NUM, pad_side=pad_side)(rpn_score)\n",
        "    selected_regions = Lambda(lambda x: x[..., :-1])(top_n_cdds)\n",
        "    selected_scores = Lambda(lambda x: x[..., -1])(top_n_cdds)\n",
        "    part_imgs = CropImage(nbox=PROPOSAL_NUM)([image_pad, selected_regions])\n",
        "    part_imgs = Lambda(lambda x: tf.stop_gradient(x))(part_imgs)\n",
        "    _, _, part_features = pretrained_model(part_imgs)\n",
        "    part_feature = Lambda(lambda x: K.reshape(x, (-1, PROPOSAL_NUM, 2048)))(part_features)\n",
        "    part_feature = Lambda(lambda x: x[:, :topN, :])(part_feature)\n",
        "    part_feature = Reshape((topN*2048,))(part_feature)\n",
        "\n",
        "    concat_out = Concatenate(axis=1)([part_feature, feature])\n",
        "    concat_logits = concat_net(concat_out)\n",
        "    raw_prob = resnet_out\n",
        "    part_prob = partcls_net(part_features)\n",
        "    part_prob = Lambda(lambda x: K.reshape(x, (-1, PROPOSAL_NUM, num_cls)))(part_prob)\n",
        "    selected_scores = Lambda(lambda x: K.reshape(x, (-1, PROPOSAL_NUM, 1)))(selected_scores)\n",
        "    concat_rank = Concatenate(axis=-1)([part_prob, selected_scores])\n",
        "    concat_rank = Reshape((PROPOSAL_NUM*(num_cls+1),), name='rank')(concat_rank)\n",
        "    part_prob = Reshape((PROPOSAL_NUM*num_cls,), name='partcls')(part_prob)\n",
        "    return keras.models.Model(input_image, [raw_prob, concat_logits, part_prob, concat_rank])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}